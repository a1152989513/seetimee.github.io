文本检测方法介绍
近些年来基于深度学习的文本检测算法层出不穷，这些方法大致可以分为两类：

基于回归的文本检测方法
基于分割的文本检测方法
本节筛选了2017-2021年的常用文本检测方法，按照如上两类方法分类如下表格所示![image](https://user-images.githubusercontent.com/50852027/153976840-fd8b6b94-5e95-4db6-8cbe-746fddb23dfa.png)
基于回归文本检测方法和目标检测算法的方法相似，文本检测方法只有两个类别，图像中的文本视为待检测的目标，其余部分视为背景。
基于回归的方法虽然在文本检测上取得了很好的效果，但是对解决弯曲文本往往难以得到平滑的文本包围曲线，并且模型较为复杂不具备性能优势。于是研究者们提出了基于图像分割的文本分割方法，
先从像素层面做分类，判别每一个像素点是否属于一个文本目标，得到文本区域的概率图，通过后处理方式得到文本分割区域的包围曲线。![image](https://user-images.githubusercontent.com/50852027/153977374-dbddb8b9-5d66-4e9b-8cc7-6d4120546691.png)
此类方法通常是基于分割的方法实现文本检测，基于分割的方法对不规则形状的文本检测有着天然的优势。基于分割的文本检测方法主体思想为，通过分割方法得到图像中文本区域，再利用opencv，polygon等后处理得到文本区域的最小包围曲线。
针对基于分割的文本算法难以区分相邻文本的问题
虽然分割方法解决了弯曲文本的检测问题，但是复杂的后处理逻辑以及预测速度也是需要优化的目标
DBNet[12]针对基于分割的方法需要使用阈值进行二值化处理而导致后处理耗时的问题，提出了可学习阈值并巧妙地设计了一个近似于阶跃函数的二值化函数，使得分割网络在训练的时候能端对端的学习文本分割的阈值。自动调节阈值不仅带来精度的提升，同时简化了后处理，提高了文本检测的性能。
```
!pip install --upgrade pip
!pip install paddleocr
```

2.1 DB文本检测算法原理
DB是一个基于分割的文本检测算法，其提出可微分阈值Differenttiable Binarization module（DB module）采用动态的阈值区分文本区域与背景。



图1 DB模型与其他方法的区别


基于分割的普通文本检测算法其流程如上图中的蓝色箭头所示，此类方法得到分割结果之后采用一个固定的阈值得到二值化的分割图，之后采用诸如像素聚类的启发式算法得到文本区域。

DB算法的流程如图中红色箭头所示，最大的不同在于DB有一个阈值图，通过网络去预测图片每个位置处的阈值，而不是采用一个固定的值，更好的分离文本背景与前景。

DB算法有以下几个优势：

算法结构简单，无需繁琐的后处理
在开源数据上拥有良好的精度和性能
在传统的图像分割算法中，获取概率图后，会使用标准二值化（Standard Binarize）方法进行处理，将低于阈值的像素点置0，高于阈值的像素点置1，,但是标准的二值化方法是不可微的，导致网络无法端对端训练。为了解决这个问题，DB算法提出了可微二值化（Differentiable Binarization，DB）。可微二值化将标准二值化中的阶跃函数进行了近似，使用如下公式进行代替
![image](https://user-images.githubusercontent.com/50852027/153996154-8e9696ce-58e9-447e-93d8-5d47f190f587.png)
其中，P是上文中获取的概率图，T是上文中获取的阈值图，k是增益因子，在实验中，根据经验选取为50。标准二值化和可微二值化的对比图如 下图3（a） 所示。
![image](https://user-images.githubusercontent.com/50852027/153996195-1ba64f4f-4681-43ec-9021-c29cceac9058.png)

当使用交叉熵损失时，正负样本的loss分别为 l+l_+l 


可以发现，增强因子会放大错误预测的梯度，从而优化模型得到更好的结果。图3（b） 中，x<0x<0x<0 的部分为正样本预测为负样本的情况，可以看到，增益因子k将梯度进行了放大；而 图3（c） 中x>0x>0x>0 的部分为负样本预测为正样本时，梯度同样也被放大了。

![image](https://user-images.githubusercontent.com/50852027/153994123-f17b1060-d272-4736-882f-d8fbea98a656.png)


图3：DB算法示意图


DB算法整体结构如下图所示：

![image](https://user-images.githubusercontent.com/50852027/153994202-c3e6e3b5-8ddf-42d5-9a1c-b21347dc06b3.png)


图2 DB模型网络结构示意图


输入的图像经过网络Backbone和FPN提取特征，提取后的特征级联在一起，得到原图四分之一大小的特征，然后利用卷积层分别得到文本区域预测概率图和阈值图，进而通过DB的后处理得到文本包围曲线。

2.2 DB文本检测模型构建
DB文本检测模型可以分为三个部分：

Backbone网络，负责提取图像的特征
FPN网络，特征金字塔结构增强特征
Head网络，计算文本区域概率图
提供的标注文件格式为：

" 图像文件名                    json.dumps编码的图像标注信息"
ch4_test_images/img_61.jpg    [{"transcription": "MASA", "points": [[310, 104], [416, 141], [418, 216], [312, 179]], ...}]
json.dumps编码前的图像标注信息是包含多个字典的list，字典中的points表示文本框的四个点的坐标(x, y)，从左上角的点开始顺时针排列。 transcription中的字段表示当前文本框的文字，在文本检测任务中并不需要这个信息。 如果您想在其他数据集上训练PaddleOCR，可以按照上述形式构建标注文件。

如果"transcription"字段的文字为'*'或者'###‘，表示对应的标注可以被忽略掉，因此，如果没有文字标签，可以将transcription字段设置为空字符串。
